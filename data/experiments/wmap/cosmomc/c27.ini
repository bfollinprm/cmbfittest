
#parameter start center, min, max, start width, st. dev. estimate
param[omegabh2] = 0.0223 0.005 0.1 0.0005 0.0005
param[omegadmh2] = 0.105 0.01 0.99 0.003 0.003
param[theta] = 1.04 0.5 10 0.0011 0.0011
param[tau] = 0.09 0.01 0.8 0.01 0.01

param[omegak] = 0 0 0 0 0
param[fnu] = 0 0 0 0 0
#param[fnu] = 0.003 0 1 0.002 0.001
param[Neff] = 3.046 3.046 3.046 0.0 0.0
param[Yp] = 0.2476 0.2476 0.2476 0 0
param[w] = -1 -1 -1 0 0
#param[w] = -1.0 -3.0 0.0 0.05 0.05

param[omegabh2_bbn] = 0.00000 0.00000 0.00000 0.000 0.000
param[Neff_bbn] = 0.00000 0.00000 0.00000 0.000 0.000
param[aeisw] = 1.00000 0.990000 1.01000 0.000 0.000
param[alens] = 1.00000 0.990000 1.01000 0.000 0.000
param[ns] = 0.961655 0.952039 0.971272 0.000 0.000
param[nt] = 0.00000 0.00000 0.00000 0.000 0.000
param[nrun] = 0.00000 0.00000 0.00000 0.000 0.000
param[logA] = 3.18816      3.17811      3.19811 0.000 0.000
param[r] = 0.00000 0.00000 0.00000 0.000 0.000
param[A_tSZ] = 5.10884 5.05776 5.15993 0.000 0.000
param[A_kSZ] = 0.00000 0.00000 0.00000 0.000 0.000
param[A_Pois] = 19.8883 19.6894 20.0872 0.0000001 0.0000001
param[A_Clust] = 4.37709 4.33332 4.42086 0.000 0.000
param[alpha] = 1.44200 1.42758 1.45642 0.000 0.000
param[beta] = 3.26200 3.22938 3.29462 0.000 0.000

file_root = chains/delete_me
chain_prefix=tmp
 
use_mpk = F
use_BAO = F
use_SNLS = F
compute_tensors = F
BBN_type = 3
use_H0_prior = F

#action = 0:  MCMC, action=1: postprocess .data file, action=2: find best fit point only
action = 0

#Maximum number of chain steps
samples = 50

#Feedback level ( 2=lots,1=chatty,0=none)
feedback = 1

#Temperature at which to Monte-Carlo
temperature = 1

#filenames for CMB datasets and SZ templates (added to C_l times parameter(13))
#Note you may need to change lmax in cmbtypes.f90 to use small scales (e.g. lmax=2100)
cmb_numdatasets = 2
cmb_dataset1 = WMAP
cmb_dataset_tSZ1 = /home/cr/paramfits/cosmomc.r11/ptsrc/dl_shaw_tsz_s10_153ghz.txt
cmb_dataset_tSZ_scale1 = 3.99
cmb_dataset_kSZ1 = 
cmb_dataset_kSZ_scale1 = 
cmb_dataset_PS_scale1 = 
cmb_dataset_CL1 = 
cmb_dataset_CL_scale1 = 

cmb_dataset2 = /data23/kstory/lps12/end2end/run_09/spt_lps12_20120828/Spectrum_spt2500deg2_lps12.newdat
cmb_dataset_tSZ2 = /home/cr/paramfits/cosmomc.r11/ptsrc/dl_shaw_tsz_s10_153ghz.txt
cmb_dataset_tSZ_scale2 = 1.0
cmb_dataset_kSZ2 = 
cmb_dataset_kSZ_scale2 = 
cmb_dataset_PS_scale2 = 1.0
cmb_dataset_CL2 = /home/cr/paramfits/cosmomc.r11/ptsrc/dl_ell0p8_shape.txt
cmb_dataset_CL_scale2 = 1.0

cmb_dataset3 = data/CBIpol_2.0_final.newdat
cmb_dataset4 = data/B03_NA_21July05.newdat

pico_datafile = /global/scratch/sd/hou/spt/paramfits/cosmomc.lps12/scripts/data/pico.tailmonty.v32.dat

#filenames for matter power spectrum datasets, incl twodf
mpk_numdatasets = 1
mpk_dataset1 = /global/scratch/sd/hou/spt/paramfits/cosmomc.lps12/data/lrgDR7kmax02kmin02newmaxLv2ALL_MAGCOVv3.dataset
#mpk_dataset1 = data/sdss_lrgDR4.dataset
#mpk_dataset1 = data/2df_2005.dataset

#filename for supernovae (default SDSS compilation)
SN_filename = data/supernovae.dataset

#filenames for BAO data sets
bao_numdatasets = 3
bao_dataset1 = /global/scratch/sd/hou/spt/paramfits/cosmomc.lps12/data/wigglez_bao.dataset
bao_dataset2 = /global/scratch/sd/hou/spt/paramfits/cosmomc.lps12/data/sdss2_bao.dataset
bao_dataset3 = /global/scratch/sd/hou/spt/paramfits/cosmomc.lps12/data/boss_bao.dataset

#if true, use HALOFIT for non-linear corrections (astro-ph/0207664).
#note lyman-alpha (lya) code assumes linear spectrum
nonlinear_pk = T

use_CMB = T
use_HST = F
use_clusters = F
use_BBN = F
use_Age_Tophat_Prior = T
use_SN = F
use_lya = F
use_min_zre = 0

use_SZ_prior = F
use_PS_prior = F
use_CL_prior = F

snls_dataset = /global/scratch/sd/hou/spt/paramfits/cosmomc.lps12/scripts/data/snls_3rdyear.dataset

#directory, e.g. window functions in directory windows under data_dir
data_dir = data/


#Force computation of sigma_8 even if use_mpk = F
get_sigma8 = T

#1: Simple Metropolis, 2: slice sampling, 3: slice sampling fast parameters, 4: directional gridding
sampling_method = 1

#if sampling_method =4, iterations per gridded direction
directional_grid_steps = 20

#use fast-slow parameter distinctions to speed up 
#(note for basic models WMAP3 code is only ~3x as fast as CAMB)
use_fast_slow = F

#Can use covariance matrix for proposal density, otherwise use settings below
#Covariance matrix can be produced using "getdist" program.
propose_matrix = 


#If propose_matrix is blank (first run), can try to use numerical Hessian to 
#estimate a good propose matrix. As a byproduct you also get an approx best fit point
estimate_propose_matrix = F

#Tolerance on log likelihood to use when estimating best fit point
delta_loglike = 2

#Scale of proposal relative to covariance; 2.4 is recommended by astro-ph/0405462 for Gaussians
#If propose_matrix is much broader than the new distribution, make proportionately smaller
#Generally make smaller if your acceptance rate is too low
propose_scale = 0.0001

#Increase to oversample fast parameters more, e.g. if space is odd shape
oversample_fast = 1

#if non-zero number of steps between sample info dumped to file file_root.data
indep_sample = 0

#number of samples to disgard at start; usually set to zero and remove later
burn_in = 0

#If zero set automatically
num_threads = 0

#MPI mode multi-chain options (recommended)
#MPI_Converge_Stop is a (variance of chain means)/(mean of variances) parameter that can be used to stop the chains
#Set to a negative number not to use this feature. Does not guarantee good accuracy of confidence limits.
MPI_Converge_Stop = 0.00001

#Do initial period of slice sampling; may be good idea if 
#cov matrix or widths are likely to be very poor estimates
MPI_StartSliceSampling  = F

#Can optionally also check for convergence of confidence limits (after MPI_Converge_Stop reached)
#Can be good idea as small value of MPI_Converge_Stop does not (necessarily) imply good exploration of tails
MPI_Check_Limit_Converge = F

#if MPI_Check_Limit_Converge = T, give tail fraction to check (checks both tails):
MPI_Limit_Converge = 0.025
#permitted quantile chain variance in units of the standard deviation (small values v slow):
MPI_Limit_Converge_Err = 0.2
#which parameter's tails to check. If zero, check all parameters:
MPI_Limit_Param = 0

#if MPI_LearnPropose = T, the proposal density is continally updated from the covariance of samples so far (since burn in)
MPI_LearnPropose = T
#can set a value of converge at which to stop updating covariance (so that it becomes rigorously Markovian)
#e.g. MPI_R_StopProposeUpdate = 0.4 will stop updating when (variance of chain means)/(mean of variances) < 0.4
MPI_R_StopProposeUpdate = 0

#If have covmat, R to reach before updating proposal density (increase if covmat likely to be poor)
#Only used if not varying new parameters that are fixed in covmat
MPI_Max_R_ProposeUpdate = 2
#As above, but used if varying new parameters that were fixed in covmat
MPI_Max_R_ProposeUpdateNew = 30

#if blank this is set from system clock
rand_seed =  

#If true, generate checkpoint files and terminated runs can be restarted using exactly the same command
#and chains continued from where they stopped
#With checkpoint=T note you must delete all chains/file_root.* files if you want new chains with an old file_root
checkpoint = F

#whether to stop on CAMB error, or continue ignoring point
stop_on_error=  T

#file used by CAMB
highL_unlensed_cl_template = camb/HighLExtrapTemplate_lenspotentialCls.dat

#CAMB parameters
#If we are including tensors
#compute_tensors = F
#Initial power spectrum amplitude point (Mpc^{-1})
#Note if you change this, may need new .covmat as degeneracy directions change
pivot_k = 0.002
#If using tensors, enforce n_T = -A_T/(8A_s)
inflation_consistency = T

#Set Y_He from BBN constraint; if false set to fixed value of 0.24 by default.
bbn_consistency = T

#Whether the CMB should be lensed (slows a lot unless also computing matter power)
CMB_lensing = T
high_accuracy_default = F
#increase accuracy_level to run CAMB on higher accuracy
#(default is about 0.3%, 0.1% if high_accuracy_default =T)
#accuracy_level can be increased to check stability/higher accuracy, but inefficient
accuracy_level = 1

#If action = 1
redo_likelihoods = T
redo_theory = F
redo_cls = F
redo_pk = F
redo_skip = 0
redo_outroot = 
redo_thin = 1
redo_add = F
redo_from_text = F
#If large difference in log likelihoods may need to offset to give sensible weights
#for exp(difference in likelihoods)
redo_likeoffset =  0


use_Yp_prior = F
Yp_mean = 0.2573
Yp_stdev = 0.0033

use_DoH_prior = F
DoH_mean = -4.556
DoH_stdev = 0.034

use_tau_prior = F
tau_mean = 0.088
tau_stdev = 0.015

H0_mean = 73.80
H0_stdev = 2.40



